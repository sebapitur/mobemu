{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn2pmml import PMMLPipeline\n",
    "from sklearn2pmml import sklearn2pmml\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MODEL\"] = \"rf\"\n",
    "os.environ[\"DATASET\"] = \"UPB2011\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"dataset/{os.environ.get('DATASET')}/useful_messages.csv\")\n",
    "positive_df = df.loc[df[\"usefulTransfer\"] == 1]\n",
    "negative_df = df.loc[df[\"usefulTransfer\"] == 0].sample(len(positive_df))\n",
    "balanced_df = pd.concat([positive_df, negative_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seba_\\mobemu\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "preprocessed_df = balanced_df.drop(columns=\"usefulTransfer\").copy()\n",
    "\n",
    "minmax_columns = [\"messageHopCount\"]\n",
    "categorial_columns = [\n",
    "    \"oldFriendWithDestination\",\n",
    "    \"oldCommonCommunity\",\n",
    "    \"newFriendWithDestination\",\n",
    "    \"newCommonCommunity\",\n",
    "]\n",
    "\n",
    "standard_columns = [\n",
    "    col\n",
    "    for col in preprocessed_df.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "    if col not in minmax_columns and col not in categorial_columns\n",
    "]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"minmax\", MinMaxScaler((0, 1)), minmax_columns),\n",
    "        (\"standard\", StandardScaler(), standard_columns),\n",
    "        (\"onehotencoder\", OneHotEncoder(), categorial_columns),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "preprocessed_df = preprocessor.fit_transform(preprocessed_df)\n",
    "X = balanced_df.copy().drop(columns=[\"usefulTransfer\"])\n",
    "result_df = pd.DataFrame(balanced_df[\"usefulTransfer\"].copy().squeeze())\n",
    "labelencoder = LabelEncoder()\n",
    "y = labelencoder.fit_transform(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_metrics(y_test, y_pred, save=False):\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    display_func = print\n",
    "\n",
    "    if save:\n",
    "        f = open(\"metrics.txt\", \"w\")\n",
    "        display_func = f.write\n",
    "\n",
    "    display_func(f\"Accuracy: {accuracy:.2f}\\n\")\n",
    "    display_func(\"Classification Report:\\n\")\n",
    "    display_func(str(classification_report(y_test, y_pred)) + '\\n')\n",
    "    display_func(\"Confusion Matrix:\\n\")\n",
    "    display_func(str(confusion_matrix(y_test, y_pred)) + '\\n')\n",
    "\n",
    "    if save:\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_neural(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    clf = MLPClassifier(\n",
    "        solver=\"lbfgs\",\n",
    "        activation=\"relu\",\n",
    "        alpha=1e-5,\n",
    "        hidden_layer_sizes=(64, 32),\n",
    "        random_state=42,\n",
    "        max_iter=500,\n",
    "    )\n",
    "\n",
    "    # Build the pipeline\n",
    "    neural_pipeline = Pipeline([(\"preprocessor\", preprocessor), (\"classifier\", clf)])\n",
    "\n",
    "    neural_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = neural_pipeline.predict(X_test)\n",
    "\n",
    "    # Create a PMML pipeline\n",
    "    pmml_pipeline = PMMLPipeline([(\"preprocessor\", preprocessor), (\"classifier\", clf)])\n",
    "\n",
    "    base_working_dir = os.getcwd()\n",
    "    os.chdir(f\"{base_working_dir}/dataset/{os.environ.get('DATASET')}\")\n",
    "    pmml_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Export the model to PMML\n",
    "    sklearn2pmml(pmml_pipeline, f\"model-rf-{os.environ.get('DATASET')}.pmml\")\n",
    "    display_metrics(y_test, y_pred, save=True)\n",
    "\n",
    "    os.chdir(base_working_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_svm(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    base = svm.SVC(kernel=\"rbf\")\n",
    "\n",
    "    # Hyperparameter tuning using Grid Search\n",
    "    param_grid = {\n",
    "        \"C\": [0.1, 1, 10],\n",
    "        \"gamma\": [\"scale\", \"auto\"],  # Kernel coefficient\n",
    "    }\n",
    "\n",
    "    grid_poly = GridSearchCV(base, param_grid, refit=True, cv=5)\n",
    "    grid_poly.fit(X_train, y_train)\n",
    "\n",
    "    best_svm = grid_poly.best_estimator_\n",
    "\n",
    "    # Build the pipeline\n",
    "    svm_pipeline = Pipeline([(\"preprocessor\", preprocessor), (\"classifier\", best_svm)])\n",
    "\n",
    "    svm_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = svm_pipeline.predict(X_test)\n",
    "\n",
    "    # Create a PMML pipeline\n",
    "    pmml_pipeline = PMMLPipeline(\n",
    "        [(\"preprocessor\", preprocessor), (\"classifier\", best_svm)]\n",
    "    )\n",
    "\n",
    "    base_working_dir = os.getcwd()\n",
    "    os.chdir(f\"{base_working_dir}/dataset/{os.environ.get('DATASET')}\")\n",
    "    pmml_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Export the model to PMML\n",
    "    sklearn2pmml(pmml_pipeline, f\"model-rf-{os.environ.get('DATASET')}.pmml\")\n",
    "    display_metrics(y_test, y_pred, save=True)\n",
    "\n",
    "    os.chdir(base_working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_random_forest(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Build the pipeline\n",
    "    rf_pipeline = Pipeline(\n",
    "        [(\"preprocessor\", preprocessor), (\"classifier\", rf_classifier)]\n",
    "    )\n",
    "\n",
    "    rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = rf_pipeline.predict(X_test)\n",
    "\n",
    "    # Create a PMML pipeline\n",
    "    pmml_pipeline = PMMLPipeline(\n",
    "        [(\"preprocessor\", preprocessor), (\"classifier\", rf_classifier)]\n",
    "    )\n",
    "\n",
    "    base_working_dir = os.getcwd()\n",
    "    os.chdir(f\"{base_working_dir}/dataset/{os.environ.get('DATASET')}\")\n",
    "    pmml_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Export the model to PMML\n",
    "    sklearn2pmml(pmml_pipeline, f\"model-rf-{os.environ.get('DATASET')}.pmml\")\n",
    "    display_metrics(y_test, y_pred, save=True)\n",
    "\n",
    "    os.chdir(base_working_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seba_\\mobemu\\.venv\\lib\\site-packages\\sklearn2pmml\\pipeline\\__init__.py:72: UserWarning: y is missing target field name(s)\n",
      "  warnings.warn(\"y is missing target field name(s)\")\n"
     ]
    }
   ],
   "source": [
    "if os.environ.get(\"MODEL\") == \"rf\":\n",
    "    train_random_forest(X, y)\n",
    "elif os.environ.get(\"MODEL\") == \"neural\":\n",
    "    train_neural(X, y)\n",
    "elif os.environ.get(\"MODEL\") == \"svm\":\n",
    "    train_svm(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
